
%SOA benchmarking
@misc{glazer2024frontiermathbenchmarkevaluatingadvanced,
      title={FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI}, 
      author={Elliot Glazer and Ege Erdil and Tamay Besiroglu and Diego Chicharro and Evan Chen and Alex Gunning and Caroline Falkman Olsson and Jean-Stanislas Denain and Anson Ho and Emily de Oliveira Santos and Olli Järviniemi and Matthew Barnett and Robert Sandler and Matej Vrzala and Jaime Sevilla and Qiuyu Ren and Elizabeth Pratt and Lionel Levine and Grant Barkley and Natalie Stewart and Bogdan Grechuk and Tetiana Grechuk and Shreepranav Varma Enugandla and Mark Wildon},
      year={2024},
      eprint={2411.04872},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2411.04872}, 
}

%Foundational mathematical theory

@book{sørensen2006lectures,
  title={Lectures on the Curry-Howard Isomorphism},
  author={S{\o}rensen, M.H. and Urzyczyn, P.},
  isbn={9780080478920},
  lccn={2006048390},
  series={Studies in Logic and the Foundations of Mathematics},
  url={https://books.google.com/books?id=_mtnm-9KtbEC},
  year={2006},
  publisher={Elsevier Science}
}


@book{robinson2001handbook,
  title={Handbook of Automated Reasoning},
  author={Robinson, A.J.A. and Voronkov, A.},
  isbn={9780080532790},
  series={Handbook of Automated Reasoning},
  url={https://books.google.com/books?id=HxaWA4lep_kC},
  year={2001},
  publisher={North Holland}
}

%%Information on Lean

@misc{carneiro2024lean4leanverifiedtypecheckerlean,
      title={Lean4Lean: Towards a Verified Typechecker for Lean, in Lean}, 
      author={Mario Carneiro},
      year={2024},
      eprint={2403.14064},
      archivePrefix={arXiv},
      primaryClass={cs.PL},
      url={https://arxiv.org/abs/2403.14064}, 
}

@inproceedings{Moura2015TheLT,
  title={The Lean Theorem Prover (System Description)},
  author={Leonardo Mendonça de Moura and Soonho Kong and Jeremy Avigad and Floris van Doorn and Jakob von Raumer},
  booktitle={CADE},
  year={2015},
  url={https://api.semanticscholar.org/CorpusID:232990}
}

%Papers on training data extraction and model training

@inproceedings{yang2023leandojo,
    title={{LeanDojo}: Theorem Proving with Retrieval-Augmented Language Models},
    author={Yang, Kaiyu and Swope, Aidan and Gu, Alex and Chalamala, Rahul and Song, Peiyang and Yu, Shixing and Godil, Saad and Prenger, Ryan and Anandkumar, Anima},
    booktitle={Neural Information Processing Systems (NeurIPS)},
    year={2023}
}

%The following N = 4 have not been read carefully. 

@misc{lample2022hypertreeproofsearchneural,
      title={HyperTree Proof Search for Neural Theorem Proving}, 
      author={Guillaume Lample and Marie-Anne Lachaux and Thibaut Lavril and Xavier Martinet and Amaury Hayat and Gabriel Ebner and Aurélien Rodriguez and Timothée Lacroix},
      year={2022},
      eprint={2205.11491},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2205.11491}, 
}

@misc{wu2024internlm25stepproveradvancingautomatedtheorem,
      title={InternLM2.5-StepProver: Advancing Automated Theorem Proving via Expert Iteration on Large-Scale LEAN Problems}, 
      author={Zijian Wu and Suozhi Huang and Zhejian Zhou and Huaiyuan Ying and Jiayu Wang and Dahua Lin and Kai Chen},
      year={2024},
      eprint={2410.15700},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2410.15700}, 
}

@misc{kumarappan2024leanagentlifelonglearningformal,
      title={LeanAgent: Lifelong Learning for Formal Theorem Proving}, 
      author={Adarsh Kumarappan and Mo Tiwari and Peiyang Song and Robert Joseph George and Chaowei Xiao and Anima Anandkumar},
      year={2024},
      eprint={2410.06209},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.06209}, 
}

@misc{xin2024deepseekproveradvancingtheoremproving,
      title={DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data}, 
      author={Huajian Xin and Daya Guo and Zhihong Shao and Zhizhou Ren and Qihao Zhu and Bo Liu and Chong Ruan and Wenda Li and Xiaodan Liang},
      year={2024},
      eprint={2405.14333},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2405.14333}, 
}

%Add in at least all the papers that you've printed out. Think about them. 

%%Perhaps this one is good for training techniques. It's orthogonal, somewhat, to what's explored in the literature. 

@inproceedings{libraryLearningBayesian,
 author = {Ellis, Kevin and Morales, Lucas and Sabl\'{e}-Meyer, Mathias and Solar-Lezama, Armando and Tenenbaum, Josh},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning Libraries of Subroutines for Neurally\textendash Guided Bayesian Program Induction},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/7aa685b3b1dc1d6780bf36f7340078c9-Paper.pdf},
 volume = {31},
 year = {2018}
}

%%There are perhaps good ideas to take from here. 

@misc{ellis2020dreamcodergrowinggeneralizableinterpretable,
      title={DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep Bayesian program learning}, 
      author={Kevin Ellis and Catherine Wong and Maxwell Nye and Mathias Sable-Meyer and Luc Cary and Lucas Morales and Luke Hewitt and Armando Solar-Lezama and Joshua B. Tenenbaum},
      year={2020},
      eprint={2006.08381},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2006.08381}, 
}